{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be8f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# data preprocessing:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# evaluation:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4b241",
   "metadata": {},
   "source": [
    "# 0. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519f6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Year_of_op</th>\n",
       "      <th>Nbr_of_nodes</th>\n",
       "      <th>Surv_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Year_of_op  Nbr_of_nodes  Surv_status\n",
       "0   30          64             1            1\n",
       "1   30          62             3            1\n",
       "2   30          65             0            1\n",
       "3   31          59             2            1\n",
       "4   31          65             4            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"haberman.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd475d",
   "metadata": {},
   "source": [
    "# 1. Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7992a4",
   "metadata": {},
   "source": [
    "We preprocess the data same way we did in the project one which consisted the removement of outliers (too high values in Number of node column), balancing the data, normalizing the data, recoding the output variable and dividing the data into training and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293220f",
   "metadata": {},
   "source": [
    "**1.1. Removing the outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae440487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with too high value in Number of node column:\n",
      "      Age  Year_of_op  Nbr_of_nodes  Surv_status\n",
      "62    43          58            52            2\n",
      "174   54          67            46            1\n",
      "215   59          62            35            2\n"
     ]
    }
   ],
   "source": [
    "a = data[data[\"Nbr_of_nodes\"] > 30]\n",
    "print(\"Observations with too high value in Number of node column:\\n\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54861665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing those three observations:\n",
    "data = data.drop([62, 174, 215])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b1050",
   "metadata": {},
   "source": [
    "**1.2. Recoding the output variable (Survival status)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b1651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Surv_status\"] = data[\"Surv_status\"].replace([1, 2], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1bb07e",
   "metadata": {},
   "source": [
    "**1.3. Dividing the data into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e211033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (212, 3)\n",
      "Test set size: (91, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(columns=[\"Surv_status\"]), data[\"Surv_status\"],\n",
    "                                                   test_size=0.3, random_state=50, stratify=data[\"Surv_status\"])\n",
    "print(\"Train set size:\", x_train.shape)\n",
    "print(\"Test set size:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81bc3a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train output values:\n",
      "0    157\n",
      "1     55\n",
      "Name: Surv_status, dtype: int64\n",
      "\n",
      "Test output values:\n",
      "0    67\n",
      "1    24\n",
      "Name: Surv_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train output values:\\n\" + str(y_train.value_counts()))\n",
    "print(\"\\nTest output values:\\n\" + str(y_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d61b8",
   "metadata": {},
   "source": [
    "**1.4. Balancing the data (using SMOTE method)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95273fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set output size:\n",
      "0    157\n",
      "1    157\n",
      "Name: Surv_status, dtype: int64\n",
      "\n",
      "Test set output size:\n",
      "0    67\n",
      "1    67\n",
      "Name: Surv_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=5)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "x_test, y_test = sm.fit_resample(x_test, y_test)\n",
    "print(\"Train set output size:\\n\" + str(y_train.value_counts()))\n",
    "print(\"\\nTest set output size:\\n\" + str(y_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba96f74",
   "metadata": {},
   "source": [
    "**1.5. Normalizing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d350bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1cdee6",
   "metadata": {},
   "source": [
    "# 2. The logistic regression model from the project one (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710bb40",
   "metadata": {},
   "source": [
    "In the project one we implemented four machine learning models which were; logistic regression, logistic ridge regression, logistic lasso regression and logistic elastic net regression. After evaluating and comparing the models we saw that the logistic regression model without the regularization was the best one for our data. Becuase of that we will now implement the logistic regression model same way we did it in the project one to set it as an baseline for this project's models. In the end of this project it is interesting to compare all the models including logistic regression model to saw which one is the best for our data.\n",
    "\n",
    "We will build the logistic regression model by only using number of nodes variable as an explanatory variable beacause we saw that with the other two explanatory variables the model got worse evaluation metrics than the model with only number of nodes explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:\n",
    "x_train_mod = x_train[:,2].reshape([len(x_train), 1])\n",
    "regressor = LogisticRegression()\n",
    "regressor_trnd = regressor.fit(x_train_mod, y_train)\n",
    "\n",
    "# predicting:\n",
    "x_test_mod = x_test[:,2].reshape([len(x_test), 1])\n",
    "y_pred = regressor_trnd.predict(x_test_mod)\n",
    "y_pred_prob = regressor_trnd.predict_proba(x_test_mod)\n",
    "\n",
    "# evaluating:\n",
    "print(\"*** LOGISTIC REGRESSION EVALUATION: ***\")\n",
    "cm_n = confusion_matrix(y_test, y_pred) \n",
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"tn:\", tn_lr, \",\", \"fp:\", fp_lr, \",\", \"fn:\", fn_lr, \",\", \"tp:\", tp_lr)\n",
    "# accuracy:\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy_lr, 2))\n",
    "# sensitivity:\n",
    "sensitivity_lr = recall_score(y_test, y_pred)\n",
    "print(\"Sensitivity:\", round(sensitivity_lr, 2))\n",
    "# classification report:\n",
    "names = [\"surv. status >= 5 years\", \"surv. status < 5 years\"]\n",
    "print(classification_report(y_test, y_pred, target_names=names))\n",
    "\n",
    "# computing the ROC curve and AUC\n",
    "fpr_lr, tpr_lr, treshold_lr = roc_curve(y_test, y_pred_prob[:,1])\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "# plotting\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(fpr_lr, tpr_lr, \"b\", label=\"AUC: \"+str(round(auc_lr, 3)))\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0, 1]), plt.ylim([0, 1])\n",
    "plt.title(\"ROC logistic regression\")\n",
    "plt.xlabel(\"False positive rate\"), plt.ylabel(\"True positive rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fcfffb",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d35d4e",
   "metadata": {},
   "source": [
    "After implementing and analyzing the parametric models (project one) we implement five non-parametric models and analyze their performance. We are going to implement three supervised learning models and two unsupervised learning models, which are K-Nearest Neighbours, Boosted trees, Artificial neural network, K-Means and DBSCAN. K-Means and DBSCAN models are unsupervised learning models.\n",
    "\n",
    "After implementing the models we will analyze and compare their performance and pick the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1efae",
   "metadata": {},
   "source": [
    "# 3.1. K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b0b43",
   "metadata": {},
   "source": [
    "We start with K-nearest neighbors classifier which is supervised learning model. The way how the model works is that it classifies the new observation based on the k nearest data points. For example if the k is five and three of the closest data points belongs to class one, the model classifies the new data point belonging to class one. So when we start to implement the model we have to find the optimal value of k. For that we use cross-validation and to score the models with a different k values we use accuracy because it takes into account the both true positive and negative classifications. After finding the optimal k-value we calculate some model evaluation merits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal k\n",
    "param_grid = {\"n_neighbors\": range(1, 30)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, scoring=\"accuracy\", cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The optimal k:\", grid.best_params_)\n",
    "print(\"The best accuracy score:\", grid.best_score_)\n",
    "\n",
    "# plotting the scores\n",
    "scores = np.array(grid.cv_results_[\"mean_test_score\"])\n",
    "n_of_k = np.array(param_grid[\"n_neighbors\"])\n",
    "plt.figure()\n",
    "plt.plot(n_of_k, scores, \"o-\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084ebc4",
   "metadata": {},
   "source": [
    "From figure we can see that models with the k one and two got equal and the best accuracy score. Next we try to do cross-validation with three folds to hopefully make our decision easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_neighbors\": range(1, 30)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, scoring=\"accuracy\", cv=3)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The optimal k:\", grid.best_params_)\n",
    "print(\"The best accuracy score:\", grid.best_score_)\n",
    "\n",
    "# plotting the scores\n",
    "scores = np.array(grid.cv_results_[\"mean_test_score\"])\n",
    "n_of_k = np.array(param_grid[\"n_neighbors\"])\n",
    "plt.figure()\n",
    "plt.plot(n_of_k, scores, \"o-\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d50f2a",
   "metadata": {},
   "source": [
    "With three folds we got little bit different result. Because k=2 got the best score in both cross-validtions we pick it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839b65b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# implementig the model with k=2\n",
    "knn_model = KNeighborsClassifier(n_neighbors=2).fit(x_train, y_train)\n",
    "y_pred = knn_model.predict(x_test)\n",
    "y_pred_prob = knn_model.predict_proba(x_test)\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"*** K-NN EVALUATION: ***\")\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "tn_knn, fp_knn, fn_knn, tp_knn = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"tn:\", tn_knn, \",\", \"fp:\", fp_knn, \",\", \"fn:\", fn_knn, \",\", \"tp:\", tp_knn)\n",
    "# accuracy:\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy_knn, 2))\n",
    "# sensitivity:\n",
    "sensitivity_knn = recall_score(y_test, y_pred)\n",
    "print(\"Sensitivity:\", round(sensitivity_knn, 2))\n",
    "# classification report:\n",
    "names = [\"surv. status >= 5 years\", \"surv. status < 5 years\"]\n",
    "print(classification_report(y_test, y_pred, target_names=names))\n",
    "\n",
    "# ROC curve and AUC\n",
    "fpr_knn, tpr_knn, treshold_knn = roc_curve(y_test, y_pred_prob[:,1])\n",
    "auc_knn = auc(fpr_knn, tpr_knn)\n",
    "# plotting\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(fpr_knn, tpr_knn, \"b\", label=\"AUC: \"+str(round(auc_knn, 3)))\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0, 1]), plt.ylim([0, 1])\n",
    "plt.title(\"ROC of K-NN\")\n",
    "plt.xlabel(\"False positive rate\"), plt.ylabel(\"True positive rate\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33807fc2",
   "metadata": {},
   "source": [
    "**THE K-NN MODEL EVALUATION:**\n",
    "- **The accuracy = 0.55:** Shows that the model classified only little bit over half of the test set patients correctly.\n",
    "- **The precision:** Shows that the model classified correctly 53% of the test set's patients which it classified to belong to the class survival status five or more years and 65% of the patients which it classified to belong to the survival status less than five years class.\n",
    "- **The recall:** Shows that the model classified the patients who belong to the class survival status five or more years 88% correctly and the most of the patients who belong to the class survival status less than five years wrong (only 22% correctly).\n",
    "- **F1-score:** Because the f1-score is the average of the precision and recall it allows us to compare which class the model classified better. Because the class with the survival status five or more years has higher score than less than five years class the model classified it better.\n",
    "\n",
    "**As an conclusion we can say that model did not perform well to classify the test set because the evaluation scores are pretty low. Also the AUC value is not so good.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a28cb",
   "metadata": {},
   "source": [
    "# 3.2. Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39859991",
   "metadata": {},
   "source": [
    "Next we implement the Gradient boosting trees model which consists many simple decision trees but the difference to the Random forest models is that in Gradient boosting trees every new decision tree in model tries to correct the error the previous ones has done. The way this method practically works is that when the model starts to train new tree to the model the observations previous trees classified wrong has a weight over one so this new tree has bigger probability to classify those obervations right. When all the decision trees have been trained the classification of the new data is a linear combination of the individual decision trees classifications.\n",
    "\n",
    "When starting to implement the Gradient boosting trees model we have to optimize three parameters which are number of estimators, learning rate and maximum depth. Number of estimators means the amount of decision trees in the model. Learning rate is a parameter which tries to prevent model not to overfit. When setting learning rate small the model \"can't learn so well\". The maximum depth parameter defines how many variables the decision trees consists. Because the idea in the Gradient boosting trees is that we combine many bad performing trees, we wan't to set the depth of trees pretty small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal parameters:\n",
    "model = GradientBoostingClassifier(random_state=5)\n",
    "param_grid = {\"n_estimators\" : [50, 100, 200, 500, 1000],\n",
    "             \"learning_rate\" : [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "             \"max_depth\" : [1, 2, 3]}\n",
    "grid = GridSearchCV(model, param_grid, scoring=\"accuracy\", cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Optimal parameters:\", grid.best_params_)\n",
    "print(\"The best accuracy score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4727dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model using the optimal parameters:\n",
    "model = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=500, random_state=5).fit(x_train, y_train)\n",
    "# prediction:\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_prob = model.predict_proba(x_test)\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"*** GRADIENT BOOSTING TREES EVALUATION: ***\")\n",
    "cm_gbt = confusion_matrix(y_test, y_pred)\n",
    "tn_gbt, fp_gbt, fn_gbt, tp_gbt = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"tn:\", tn_gbt, \",\", \"fp:\", fp_gbt, \",\", \"fn:\", fn_gbt, \",\", \"tp:\", tp_gbt)\n",
    "# accuracy:\n",
    "accuracy_gbt = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy_gbt, 2))\n",
    "# sensitivity:\n",
    "sensitivity_gbt = recall_score(y_test, y_pred)\n",
    "print(\"Sensitivity:\", round(sensitivity_gbt, 2))\n",
    "# classification report:\n",
    "names = [\"surv. status >= 5 years\", \"surv. status < 5 years\"]\n",
    "print(classification_report(y_test, y_pred, target_names=names))\n",
    "\n",
    "# ROC curve and AUC\n",
    "fpr_gbt, tpr_gbt, treshold_gbt = roc_curve(y_test, y_pred_prob[:,1])\n",
    "auc_gbt = auc(fpr_gbt, tpr_gbt)\n",
    "# plotting\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(fpr_gbt, tpr_gbt, \"b\", label=\"AUC: \"+str(round(auc_gbt, 3)))\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0, 1]), plt.ylim([0, 1])\n",
    "plt.title(\"ROC of GBT\")\n",
    "plt.xlabel(\"False positive rate\"), plt.ylabel(\"True positive rate\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84981027",
   "metadata": {},
   "source": [
    "**THE GRADIENT BOOSTING TREES MODEL EVALUATION:**\n",
    "- **The accuracy = 0.57:** Shows that the model classified almost 60% of the test dataset correctly.\n",
    "- **The precision:** Tells us that the model classified 56% of the patients correctly which it classified to belong to the survival status five or more years class and 60% of the patients correctly which it classified to belong to the survival status less than five years class.\n",
    "- **The recall:** Shows us that from all the patients who belong to the survival status five or more years class the model classified correctly 69% and from all the patients who belong to the survival status less than five years class the model classified correctly only 46%.\n",
    "- **The F1-score:** Shows that the model classified better the class survival status five or more years but actually not so good either class.\n",
    "\n",
    "**As a conclusion we can say that the Gradient boosting trees model didn't perform well in classifying the test dataset because the accuracy, precision, recall, AUC and f1-scores are pretty low.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f35ef",
   "metadata": {},
   "source": [
    "**----------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022abe12",
   "metadata": {},
   "source": [
    "**Next** we examine the importance of the variables in this model by examining the importance score of the input variables. Basically the importance score means that the higher the score is the more the variable is used in the model's trees to classify the patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, [\"Age\", \"Year of op.\", \"Number of nodes\"])\n",
    "plt.figure()\n",
    "importances.plot.bar()\n",
    "plt.ylabel(\"Variable importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c563a790",
   "metadata": {},
   "source": [
    "From the figure we can see that the Age variable seems to be the most important variable in this model which is totally different result than we get in our baseline model. In our baseline model (logistic regression) we saw that only Number of nodes variable is statistically significant which means that Age and Year of operation variables are insignificant when classifiyng the patients. When we compare the evaluation metrics between this model and baseline model we can see that the baseline model classified better the test set patients than this model so it seems that maybe Number of node variable is actually more important when classifiyng the patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec479e",
   "metadata": {},
   "source": [
    "# 3.3. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785f558",
   "metadata": {},
   "source": [
    "Next we implement our last supervised learning model which is artificial neural network model Multilayer perceptron. Artificial neural network models tries to copy biological neural networks. The artificial neural networks consist of input layer, hidden layer/layers (can have differet amount of hidden layers) and output layer which consist of nodes. The activation functions are used to calculate if the node will activate or not based on the previous layer's nodes. \n",
    "\n",
    "Artificial neural network models has a lot of factors to be determined for example activation functions between different layers, the amount of hidden layers, learning rate etc. Because of that we are not going to search the optimal option for all of the factors. What we are going to do is that we use the default options in most of the factors and we will optimize the amount of hidden layers and nodes in hidden layers and the weight of the regularization term (= alpha). As an activation function between the hidden layers we will use the rectified linear unit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d6f39ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters: {'alpha': 0.01, 'hidden_layer_sizes': (10, 10)}\n",
      "The accuracy score: 0.6528929851510495\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# finding the optimal parameters\n",
    "param_grid = {\"alpha\" : [1e-2, 1, 5, 10, 20, 30], \n",
    "             \"hidden_layer_sizes\" : [(5,), (10,), (5,5), (10,10), (5,10), (10,5), (15,15)]} # (amount of nodes, amount of layers)\n",
    "grid = GridSearchCV(MLPClassifier(random_state=3), param_grid, scoring=\"accuracy\", cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The optimal parameters:\", grid.best_params_)\n",
    "print(\"The accuracy score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d32cc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the model using optimal parameters\n",
    "model = MLPClassifier(random_state=3, alpha=0.01, hidden_layer_sizes=(10,10)).fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_prob = model.predict_proba(x_test)\n",
    "\n",
    "# evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ad54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
